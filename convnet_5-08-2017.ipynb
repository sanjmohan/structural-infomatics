{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Q8 Classification -- 5/07/2017\n",
    "\n",
    "https://arxiv.org/pdf/1702.03865.pdf\n",
    "\n",
    "Testing:\n",
    "- simplified google brain conv model\n",
    " - multiscale conv nets\n",
    " - skip connection\n",
    " - batch norm\n",
    "- convolutional downsampling before final dense layer for limited gpu memory\n",
    "- learning rate scheduling (single decrease after 20 epochs)\n",
    "- stochastic and minibatch (ie size 4) for limited gpu memory\n",
    "- functional keras api\n",
    "\n",
    "Results:\n",
    "- cpu: 1 epoch 900s (lol)\n",
    "- gpu: \n",
    " - ~10 epochs, 72s/e, ~56% (4 filters in final conv)\n",
    " - ~25 epochs, 211s/e, 58.67% (12 filters final conv), minibatch 4, l2 0.05, lr 0.001\n",
    " - 21 epochs, 210s/e. 59.68%, 12 filters, minibatch 4, l2 0.025, lr 0.001, 0.0002 after 20\n",
    " - 21 epochs, 473s/e, 60.31%, 14 filters, minibatch 4, l2 0.025, lr 0.001, 0.0001 after 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import cullpdb_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Constants and Hyperparameters\n",
    "Declare constants about data such as the length of a protein and the number of possible residues and classes.\n",
    "<br><br>\n",
    "Declare hyperparameters about model such as learning rate, number of epochs of training (how many iterations through the entire data set to train for), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_RESIDUES = 700           # per protein\n",
    "RESIDUE_SIZE = 22   \n",
    "NUM_CLASSES = 9              # 8 + 'NoSeq'\n",
    "PSSM_SIZE = 22\n",
    "NUM_FEATURES = RESIDUE_SIZE  # size of one hot vector per residue\n",
    "\n",
    "PSSM = True\n",
    "if PSSM:\n",
    "    NUM_FEATURES += PSSM_SIZE\n",
    "\n",
    "INPUT_SHAPE = (NUM_RESIDUES, NUM_FEATURES)\n",
    "OUTPUT_SIZE = NUM_CLASSES*NUM_RESIDUES      # output matrix holding predictions\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "# regularization factor\n",
    "L2 = 0.025\n",
    "EPOCHS = 30\n",
    "MINIBATCH = 2\n",
    "LOSS='categorical_crossentropy'\n",
    "OPTIMIZER = optimizers.Adam(lr=LEARNING_RATE)\n",
    "\n",
    "SHOW_ACCURACY = True  # set to False for quicker train ops\n",
    "\n",
    "SAVE_FILE = \"models/conv-filtered-5-08.h5py\"\n",
    "DATA = \"data/cullpdb+profile_6133.npy.gz\"\n",
    "DATA_FILTERED = \"data/cullpdb+profile_6133_filtered.npy.gz\"\n",
    "DATA_TEST = \"data/cb513+profile_split1.npy.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Data\n",
    "<b>Data:</b><br> _x represents input proteins, _y represents target structure classifications (each as one-hot vectors) <br><br>\n",
    "<b>Data Shape:</b><br> First dimension represents number of proteins, second number of residues per protein, and third size of residue or structure vector.<br> For example, train_x without pssm is shape (5600, 700, 22): it is an <b>m \\* n \\* p</b> matrix where there are <b>m</b> proteins (each row), <b>n</b> residues per protein (each column), and <b>p</b> sized vectors to represent a single residue or a single structure (each \"slice\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading protein residues and labels...\n",
      "Loading file from C:\\SANJAY\\CS\\Projects\\sdscbio\\data\\cullpdb+profile_6133_filtered.npy.gz...\n",
      "File Loaded.\n",
      "Loaded protein residues and labels.\n",
      "Reshaping...\n",
      "Reshaped\n",
      "Loading file from C:\\SANJAY\\CS\\Projects\\sdscbio\\data\\cb513+profile_split1.npy.gz...\n",
      "File Loaded.\n"
     ]
    }
   ],
   "source": [
    "train = cullpdb_loader.load_residues(DATA_FILTERED, split=False, two_d=True, pssm=PSSM)  # load from my helper file\n",
    "\n",
    "test = cullpdb_loader.load_cb513(DATA_TEST, two_d=True, pssm=PSSM)\n",
    "\n",
    "# train, validation, and test were loaded as tuples of (input, output);\n",
    "train_x, train_y = train\n",
    "test_x, test_y = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residues:\n",
      "FDYQTVYFANQYGLRTIELGESEFVDNTLDNQHKXVIKAAWGGGYTNRNNVVINFKVDESLCDNLYFKDTDQPLVPXPASYYTLASDRIAIPKGQIXAGVEVQLTDDFFADEKSISENYVIPLLXTNVQGADSILQGKPVVENPVLTNAGDWSILPQNFVLYAVKYVNPWHGEYLRRGIDHATVAGTSKDIIRHEQFVENDEVVNISTKSXKDNLLTLKTKDESGKDISYTVRLSFAEDGSCTVHSGSQNVVVSGSGKFVSKGEKNSLGGKDRNAIYLDYTVNLTDNNIQLATKDTLVLRTRNVYGGKSLEVVRK-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Labels:\n",
      "LLLLEEELSLSEEEEEEELSLLSSSLLHHHHTTEEEEEEEEESSSSLLSLEEEEEEELGGGGTTLEETTTLLBLEELLGGGEEESLSEEEELTTLSEEEEEEEELHHHHHSGGGGSSLEEEEEEEEEEESSSEELLLEESSSSLLTTLGGGEEELLLSEEEEEEEEELTTLEEEEEEEEEEEEETTEEEEEEELLSSGGGSEEEEEEESSSSEEEEEEEEELTTSLEEEEEEEEEELTTSEEEEEELSTTLEEEEEEEEEEEEETTLGGGSLEEEEEEEEEEEETTTTEEEEEEEEEEEEELLLLSEEELLEELL-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_x: (5534, 700, 44)\n",
      "train_y (5534, 700, 9)\n",
      "test_x: (514, 700, 44)\n",
      "test_y: (514, 700, 9)\n"
     ]
    }
   ],
   "source": [
    "# print a protein to see example representation (with character labels instead of one-hot vectors)\n",
    "cullpdb_loader.print_residues(train_x[0], labels=train_y[0], two_d=True)\n",
    "\n",
    "# print to verify data was loaded in correct shapes:\n",
    "print(\"train_x:\", train_x.shape)\n",
    "print(\"train_y\", train_y.shape)\n",
    "print(\"test_x:\", test_x.shape)\n",
    "print(\"test_y:\", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Custom Accuracy Metric\n",
    "\n",
    "The default Keras accuracy metric does not compare observations and targets over multiple dimensions. A custom method to find  accuracy must be defined.\n",
    "<br><br>\n",
    "Here, a <b>mask</b> is created -- a matrix with ones where the target labels have labels that are not 'NoSeq', and zeros where the target labels are 'NoSeq'. We can then do a comparison between observed and target labels, and by multiplying the resulting boolean matrix by this mask, we ignore any right/wrong labels in the trailing 'NoSeq' region (that exists only to pad the protein to the correct length).\n",
    "<br><br>\n",
    "This gives an accuracy metric depending only on the non-'NoSeq' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Second custom accuracy: ignore trailing noseq's\n",
    "def custom_acc(true, obs):\n",
    "    print(\"Using custom accuracy\")\n",
    "    if not SHOW_ACCURACY:\n",
    "        return K.constant(float('NaN'))\n",
    "    \n",
    "    # -1 = placeholder for whatever's left\n",
    "    obs = K.reshape(obs, [-1, 700, 9])\n",
    "    true = K.reshape(true, [-1, 700, 9])\n",
    "    \n",
    "    # convert one-hot vectors for residues to scalars\n",
    "    true_vals = K.argmax(true, axis=2)\n",
    "    obs_vals = K.argmax(obs, axis=2)\n",
    "    \n",
    "    # mask is 2D matrix with 1s in indices that are residues\n",
    "    # and 0s in indices that are 'NoSeq'\n",
    "    # subtract all 8's to shift 'NoSeq' values to zero\n",
    "    mask = K.sign(K.abs(true_vals - 8*K.ones_like(true_vals, dtype='int64')))\n",
    "    mask = K.cast(mask, dtype=K.floatx())\n",
    "    # 1D vector with each index the number of non-'NoSeq' residues \n",
    "    # in corresponding protein\n",
    "    length = K.sum(mask, axis=1)\n",
    "    \n",
    "    # compare observed and predicted values (cast from boolean to 1s and 0s),\n",
    "    # then multiply by mask to nullify any trailing 'NoSeq' equalities\n",
    "    comparison = K.cast(K.equal(true_vals, obs_vals), dtype=K.floatx())\n",
    "    comparison = comparison * mask\n",
    "    \n",
    "    # and return average\n",
    "    return K.sum(comparison) / K.sum(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_sched(epoch):\n",
    "    if epoch >= 20:\n",
    "        return LEARNING_RATE / 10\n",
    "    else:\n",
    "        return LEARNING_RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Block of convolutional and batch norm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_block(input_tensor):\n",
    "    # 3 parallel convolutions\n",
    "    c1 = layers.convolutional.Conv1D(32, 3, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    c2 = layers.convolutional.Conv1D(32, 7, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    c3 = layers.convolutional.Conv1D(32, 9, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    \n",
    "    # depth stack of 3 convolutions with batch norm\n",
    "    merge1 = layers.concatenate([c1, c2, c3])\n",
    "    merge1 = layers.normalization.BatchNormalization()(merge1)\n",
    "    \n",
    "    # final singe convolution with batch norm\n",
    "    c4 = layers.convolutional.Conv1D(16, 9, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(merge1)\n",
    "    c4 = layers.normalization.BatchNormalization()(c4)\n",
    "    \n",
    "    # 1-window conv on inputs\n",
    "    c_skip = layers.convolutional.Conv1D(1, 1, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    c_skip = layers.normalization.BatchNormalization()(c_skip)\n",
    "    \n",
    "    # depth concat of last conv, middle conv, and skip connection\n",
    "    merge2 = layers.concatenate([c4, merge1, c_skip])\n",
    "    \n",
    "    return merge2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Architecture\n",
    "Using only one final fully connected layer; including convolutional layer before final feedforward layer to significantly reduce feature dimensionality.\n",
    "![](architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\ipykernel\\__main__.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"Ou...)`\n"
     ]
    }
   ],
   "source": [
    "input_tensor = layers.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "block1 = add_block(input_tensor)\n",
    "\n",
    "block2 = add_block(block1)\n",
    "\n",
    "conv = layers.convolutional.Conv1D(14, 5, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(block2)\n",
    "\n",
    "flat = layers.Flatten()(conv)\n",
    "\n",
    "output = layers.Dense(OUTPUT_SIZE, name=\"OutputLayer\", activation='softmax',\n",
    "        kernel_regularizer=regularizers.l2(L2))(flat)\n",
    "\n",
    "model = Model(inputs=input_tensor, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Compile the model given a loss function, optimizer, and learning rate (specified above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom accuracy\n"
     ]
    }
   ],
   "source": [
    "# optimizer= takes either string or optimizer object\n",
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[custom_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 700, 44)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 700, 32)       4256                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, 700, 32)       9888                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                (None, 700, 32)       12704                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 700, 96)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 700, 96)       384                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 700, 16)       13840                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 700, 1)        45                                           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 700, 16)       64                                           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 700, 1)        4                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 700, 113)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 700, 32)       10880                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)                (None, 700, 32)       25344                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)                (None, 700, 32)       32576                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 700, 96)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 700, 96)       384                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)                (None, 700, 16)       13840                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)               (None, 700, 1)        114                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 700, 16)       64                                           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 700, 1)        4                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 700, 113)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)               (None, 700, 14)       7924                                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 9800)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "OutputLayer (Dense)              (None, 6300)          61746300                                     \n",
      "====================================================================================================\n",
      "Total params: 61,878,615.0\n",
      "Trainable params: 61,878,163.0\n",
      "Non-trainable params: 452.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the model on training data against target training labels, show accuracy on validation data each epoch\n",
    "Here, the <b>val_loss</b> and <b>val_acc</b> are the loss and accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5534 samples, validate on 514 samples\n",
      "Epoch 1/150\n",
      "475s - loss: 5046.3952 - custom_acc: 0.4541 - val_loss: 5008.6993 - val_custom_acc: 0.5067\n",
      "Epoch 2/150\n",
      "473s - loss: 4983.3623 - custom_acc: 0.5752 - val_loss: 4939.2309 - val_custom_acc: 0.5461\n",
      "Epoch 3/150\n",
      "473s - loss: 4970.7465 - custom_acc: 0.6023 - val_loss: 4943.2071 - val_custom_acc: 0.5527\n",
      "Epoch 4/150\n",
      "473s - loss: 4966.8126 - custom_acc: 0.6143 - val_loss: 4945.0666 - val_custom_acc: 0.5655\n",
      "Epoch 5/150\n",
      "476s - loss: 4967.0829 - custom_acc: 0.6200 - val_loss: 5538.5872 - val_custom_acc: 0.4275\n",
      "Epoch 6/150\n",
      "473s - loss: 4961.9038 - custom_acc: 0.6293 - val_loss: 4935.9578 - val_custom_acc: 0.5679\n",
      "Epoch 7/150\n",
      "473s - loss: 4959.6662 - custom_acc: 0.6329 - val_loss: 4945.0405 - val_custom_acc: 0.5678\n",
      "Epoch 8/150\n",
      "473s - loss: 4958.2891 - custom_acc: 0.6364 - val_loss: 4952.7393 - val_custom_acc: 0.5756\n",
      "Epoch 9/150\n",
      "473s - loss: 4957.1916 - custom_acc: 0.6395 - val_loss: 4932.0491 - val_custom_acc: 0.5737\n",
      "Epoch 10/150\n",
      "473s - loss: 4955.5646 - custom_acc: 0.6422 - val_loss: 4964.6889 - val_custom_acc: 0.5646\n",
      "Epoch 11/150\n",
      "473s - loss: 4955.1167 - custom_acc: 0.6440 - val_loss: 4942.2549 - val_custom_acc: 0.5801\n",
      "Epoch 12/150\n",
      "473s - loss: 4954.6017 - custom_acc: 0.6453 - val_loss: 4941.1962 - val_custom_acc: 0.5771\n",
      "Epoch 13/150\n",
      "473s - loss: 4954.2886 - custom_acc: 0.6470 - val_loss: 4945.9918 - val_custom_acc: 0.5792\n",
      "Epoch 14/150\n",
      "473s - loss: 4953.0070 - custom_acc: 0.6481 - val_loss: 5283.1413 - val_custom_acc: 0.5515\n",
      "Epoch 15/150\n",
      "473s - loss: 4953.1941 - custom_acc: 0.6495 - val_loss: 4948.2870 - val_custom_acc: 0.5785\n",
      "Epoch 16/150\n",
      "473s - loss: 4952.6983 - custom_acc: 0.6501 - val_loss: 4949.6622 - val_custom_acc: 0.5797\n",
      "Epoch 17/150\n",
      "473s - loss: 4951.7569 - custom_acc: 0.6520 - val_loss: 4936.0243 - val_custom_acc: 0.5747\n",
      "Epoch 18/150\n",
      "473s - loss: 4952.4617 - custom_acc: 0.6506 - val_loss: 4978.9703 - val_custom_acc: 0.5816\n",
      "Epoch 19/150\n",
      "473s - loss: 4953.0174 - custom_acc: 0.6503 - val_loss: 4958.2998 - val_custom_acc: 0.5847\n",
      "Epoch 20/150\n",
      "473s - loss: 4950.5842 - custom_acc: 0.6546 - val_loss: 4973.4772 - val_custom_acc: 0.5867\n",
      "Epoch 21/150\n",
      "473s - loss: 4865.1993 - custom_acc: 0.7485 - val_loss: 4885.5090 - val_custom_acc: 0.6031\n",
      "Epoch 22/150\n",
      "473s - loss: 4817.0760 - custom_acc: 0.7868 - val_loss: 4884.2150 - val_custom_acc: 0.6021\n",
      "Epoch 23/150\n",
      "473s - loss: 4791.9480 - custom_acc: 0.8107 - val_loss: 4885.2715 - val_custom_acc: 0.5981\n",
      "Epoch 24/150\n",
      "474s - loss: 4775.1873 - custom_acc: 0.8274 - val_loss: 4883.0129 - val_custom_acc: 0.5975\n",
      "Epoch 25/150\n",
      "474s - loss: 4764.4166 - custom_acc: 0.8388 - val_loss: 4888.3708 - val_custom_acc: 0.5941\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-05c015fc7b17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m hist = model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, verbose=2,\n\u001b[0;32m      8\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMINIBATCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                 callbacks=[keras.callbacks.LearningRateScheduler(lr_sched)])\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2073\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\sdscbio-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reshape the labels into a 2D matrix to make accuracy checks easier later on\n",
    "train_y = train_y.reshape(len(train_y), NUM_CLASSES*NUM_RESIDUES)\n",
    "test_y = test_y.reshape(len(test_y), NUM_CLASSES*NUM_RESIDUES)\n",
    "\n",
    "# Training\n",
    "# verbose: 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "hist = model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, verbose=2,\n",
    "                 batch_size=MINIBATCH, validation_data=(test_x, test_y),\n",
    "                callbacks=[keras.callbacks.LearningRateScheduler(lr_sched)])\n",
    "print(\"Done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reshape labels back to original shape\n",
    "train_y = train_y.reshape(-1, NUM_RESIDUES, NUM_CLASSES)\n",
    "test_y = test_y.reshape(-1, NUM_RESIDUES, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved.\n"
     ]
    }
   ],
   "source": [
    "model.save(SAVE_FILE)\n",
    "print(\"model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vali_loss = list(hist.history.values())[0]\n",
    "plt.plot(range(EPOCHS), vali_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test on cb513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_acc = model.evaluate(test_x, test_y)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "prediction = model.predict(test_x[i:i+1])\n",
    "print(\"Shape:\", prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Expected:\\n\")\n",
    "_ = cullpdb_loader.print_residues(test_x[i], labels=test_y[i], two_d=True)\n",
    "print(\"\\nPredicted:\\n\")\n",
    "_ = cullpdb_loader.print_residues(test_x[i], labels=prediction[0], two_d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sdscbio-gpu]",
   "language": "python",
   "name": "conda-env-sdscbio-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
