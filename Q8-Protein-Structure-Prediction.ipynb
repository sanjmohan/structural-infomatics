{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Q8 Protein Structure Prediction\n",
    "\n",
    "https://arxiv.org/pdf/1702.03865.pdf\n",
    "\n",
    "Multiscale convolutional network with bidirectional GRU layer, trained on Nvidia GTX 970M."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# display graphs within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "# my script for loading files\n",
    "import cullpdb_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Constants and Hyperparameters\n",
    "Declare constants about data such as the length of a protein and the number of possible residues and classes.\n",
    "<br><br>\n",
    "Declare hyperparameters about model such as learning rate, number of epochs of training (how many iterations through the entire data set to train for), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_RESIDUES = 700           # per protein (ie the length of each protein)\n",
    "RESIDUE_SIZE = 22\n",
    "NUM_CLASSES = 9              # 8 + 'NoSeq' -- output dimension\n",
    "PSSM_SIZE = 22\n",
    "NUM_FEATURES = RESIDUE_SIZE + PSSM_SIZE # size of one hot vector per residue\n",
    "\n",
    "INPUT_SHAPE = (NUM_RESIDUES, NUM_FEATURES)\n",
    "OUTPUT_SIZE = NUM_CLASSES\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "# regularization factor\n",
    "L2 = 0.025\n",
    "EPOCHS = 60\n",
    "MINIBATCH = 200\n",
    "LOSS='categorical_crossentropy'\n",
    "OPTIMIZER = optimizers.Adam(lr=LEARNING_RATE)\n",
    "\n",
    "SHOW_ACCURACY = True  # set to False for quicker train ops\n",
    "\n",
    "SAVE_FILE = \"models/q8pred.h5py\"\n",
    "\n",
    "DATA = \"data/cullpdb+profile_6133.npy.gz\"\n",
    "DATA_FILTERED = \"data/cullpdb+profile_6133_filtered.npy.gz\"\n",
    "DATA_TEST = \"data/cb513+profile_split1.npy.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Data\n",
    "<b>Data:</b><br> _x represents input proteins, _y represents target structure classifications (each as one-hot vectors) <br><br>\n",
    "<b>Data Shape:</b><br> The first dimension represents the number of proteins (ie the size of the dataset), second the number of residues per protein (length of each protein), and third the size of residue or structure vector.<br> For example, train_x without pssm is shape (5600, 700, 22): it is an <b>m \\* n \\* p</b> matrix where there are <b>m</b> proteins (each row), <b>n</b> residues per protein (each column), and <b>p</b> sized vectors to represent a single residue or a single structure (each \"slice\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading protein residues and labels...\n",
      "Loading file from C:\\SANJAY\\CS\\Projects\\sdscbio\\data\\cullpdb+profile_6133_filtered.npy.gz...\n",
      "File Loaded.\n",
      "Loaded protein residues and labels.\n",
      "Reshaping...\n",
      "Reshaped\n",
      "Loading file from C:\\SANJAY\\CS\\Projects\\sdscbio\\data\\cb513+profile_split1.npy.gz...\n",
      "File Loaded.\n"
     ]
    }
   ],
   "source": [
    "train = cullpdb_loader.load_residues(DATA_FILTERED, split=False, two_d=True, pssm=True)  # load from my helper file\n",
    "\n",
    "test = cullpdb_loader.load_cb513(DATA_TEST, two_d=True, pssm=True)\n",
    "\n",
    "# train, validation, and test were loaded as tuples of (input, output);\n",
    "train_x, train_y = train\n",
    "test_x, test_y = test\n",
    "\n",
    "#train_x, train_y = train_x[:10], train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residues:\n",
      "FDYQTVYFANQYGLRTIELGESEFVDNTLDNQHKXVIKAAWGGGYTNRNNVVINFKVDESLCDNLYFKDTDQPLVPXPASYYTLASDRIAIPKGQIXAGVEVQLTDDFFADEKSISENYVIPLLXTNVQGADSILQGKPVVENPVLTNAGDWSILPQNFVLYAVKYVNPWHGEYLRRGIDHATVAGTSKDIIRHEQFVENDEVVNISTKSXKDNLLTLKTKDESGKDISYTVRLSFAEDGSCTVHSGSQNVVVSGSGKFVSKGEKNSLGGKDRNAIYLDYTVNLTDNNIQLATKDTLVLRTRNVYGGKSLEVVRK-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Labels:\n",
      "LLLLEEELSLSEEEEEEELSLLSSSLLHHHHTTEEEEEEEEESSSSLLSLEEEEEEELGGGGTTLEETTTLLBLEELLGGGEEESLSEEEELTTLSEEEEEEEELHHHHHSGGGGSSLEEEEEEEEEEESSSEELLLEESSSSLLTTLGGGEEELLLSEEEEEEEEELTTLEEEEEEEEEEEEETTEEEEEEELLSSGGGSEEEEEEESSSSEEEEEEEEELTTSLEEEEEEEEEELTTSEEEEEELSTTLEEEEEEEEEEEEETTLGGGSLEEEEEEEEEEEETTTTEEEEEEEEEEEEELLLLSEEELLEELL-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_x: (5534, 700, 44)\n",
      "train_y (5534, 700, 9)\n",
      "test_x: (514, 700, 44)\n",
      "test_y: (514, 700, 9)\n"
     ]
    }
   ],
   "source": [
    "# print a protein to see example representation (with character labels instead of one-hot vectors)\n",
    "cullpdb_loader.print_residues(train_x[0], labels=train_y[0], two_d=True)\n",
    "\n",
    "# print to verify data was loaded in correct shapes:\n",
    "print(\"train_x:\", train_x.shape)\n",
    "print(\"train_y\", train_y.shape)\n",
    "print(\"test_x:\", test_x.shape)\n",
    "print(\"test_y:\", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Custom Accuracy Metric\n",
    "\n",
    "The default Keras accuracy metric does not compare observations and targets over multiple dimensions. A custom method to find  accuracy must be defined.\n",
    "<br><br>\n",
    "Here, a <b>mask</b> is created -- a matrix with ones where the target labels have labels that are not 'NoSeq', and zeros where the target labels are 'NoSeq'. We can then do a comparison between observed and target labels, and by multiplying the resulting boolean matrix by this mask, we ignore any right/wrong labels in the trailing 'NoSeq' region (that exists only to pad the protein to the correct length).\n",
    "<br><br>\n",
    "This gives an accuracy metric depending only on the non-'NoSeq' labels -- otherwise, the accuracy would be incorrectly inflated based on the easy-to-predict padding at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Second custom accuracy: ignore trailing noseq's\n",
    "def custom_acc(true, obs):\n",
    "    print(\"Using custom accuracy\")\n",
    "    if not SHOW_ACCURACY:\n",
    "        return K.constant(float('NaN'))\n",
    "        \n",
    "    # convert one-hot vectors for residues to scalars\n",
    "    true_vals = K.argmax(true, axis=2)\n",
    "    obs_vals = K.argmax(obs, axis=2)\n",
    "    \n",
    "    # mask is 2D matrix with 1s in indices that are residues\n",
    "    # and 0s in indices that are 'NoSeq'\n",
    "    # subtract all 8's to shift 'NoSeq' values to zero\n",
    "    mask = K.sign(K.abs(true_vals - 8*K.ones_like(true_vals, dtype='int64')))\n",
    "    mask = K.cast(mask, dtype=K.floatx())\n",
    "    # 1D vector with each index the number of non-'NoSeq' residues \n",
    "    # in corresponding protein\n",
    "    length = K.sum(mask, axis=1)\n",
    "    \n",
    "    # compare observed and predicted values (cast from boolean to 1s and 0s),\n",
    "    # then multiply by mask to nullify any trailing 'NoSeq' equalities\n",
    "    comparison = K.cast(K.equal(true_vals, obs_vals), dtype=K.floatx())\n",
    "    comparison = comparison * mask\n",
    "    \n",
    "    # and return average\n",
    "    return K.sum(comparison) / K.sum(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler\n",
    "Decrease learning rate after certain number of epochs to make learning smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_sched(epoch):\n",
    "    if epoch >= 30:\n",
    "        return LEARNING_RATE / 10\n",
    "    else:\n",
    "        return LEARNING_RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Block of convolutional and batch norm layers\n",
    "See picture below for layout.\n",
    "\n",
    "Each convolutional layer is a 1-dimensional convolution -- for each protein, each step of the convolution takes window-sized many residues, taking as input the entire feature slices of each of these residues. The output is a 700-length protein (obtained from 700 steps of the convolutional window, using padding on the sequence boundaries) with number of features per residue equal to the number of filters (the first parameter) of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_block(input_tensor):\n",
    "    # 3 parallel convolutions -- see image below\n",
    "    # Each has 32 filters (ie the output dimension) and window sizes of 3, 7, and 9\n",
    "    # residues respectively.\n",
    "    c1 = layers.convolutional.Conv1D(32, 3, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    c2 = layers.convolutional.Conv1D(32, 7, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    c3 = layers.convolutional.Conv1D(32, 9, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    \n",
    "    # depth stack of 3 convolutions with batch norm\n",
    "    merge1 = layers.concatenate([c1, c2, c3])\n",
    "    merge1 = layers.normalization.BatchNormalization()(merge1)\n",
    "    \n",
    "    # final singe convolution with batch norm\n",
    "    c4 = layers.convolutional.Conv1D(48, 9, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(merge1)\n",
    "    c4 = layers.normalization.BatchNormalization()(c4)\n",
    "    \n",
    "    # 1-window conv on inputs\n",
    "    c_skip = layers.convolutional.Conv1D(44, 1, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(input_tensor)\n",
    "    c_skip = layers.normalization.BatchNormalization()(c_skip)\n",
    "    \n",
    "    # depth concat of last conv, middle conv, and skip connection\n",
    "    merge2 = layers.concatenate([c4, merge1, c_skip])\n",
    "    \n",
    "    return merge2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Architecture\n",
    "Replacing fully connected layers with convolutional layer, bidirectional recurrent layer, convolutional layer.\n",
    "![](architecture.png)\n",
    "The input tensor is concatenated to maintain original representation and hopefully improve baseline prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "block1 = add_block(input_tensor)\n",
    "#block1 = input_tensor\n",
    "\n",
    "block2 = add_block(block1)\n",
    "\n",
    "conv1 = layers.convolutional.Conv1D(64, 5, \n",
    "        activation='relu', padding='same',\n",
    "        kernel_regularizer=regularizers.l2(L2))(block2)\n",
    "\n",
    "with_input = layers.concatenate([conv1, input_tensor])\n",
    "\n",
    "fbgru1 = layers.wrappers.Bidirectional(layers.recurrent.GRU(12, return_sequences=True))(with_input)\n",
    "\n",
    "output = layers.convolutional.Conv1D(OUTPUT_SIZE, 1, \n",
    "        activation='softmax', padding='same', name=\"OutputLayer\",\n",
    "        kernel_regularizer=regularizers.l2(L2))(fbgru1)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Compile the model given a loss function, optimizer, and learning rate (specified above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom accuracy\n"
     ]
    }
   ],
   "source": [
    "# optimizer= takes either string or optimizer object\n",
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[custom_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of model parameters per layer and output dimensions from each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 700, 44)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 700, 32)       4256                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, 700, 32)       9888                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                (None, 700, 32)       12704                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 700, 96)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 700, 96)       384                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 700, 48)       41520                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 700, 44)       1980                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 700, 48)       192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 700, 44)       176                                          \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 700, 188)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 700, 32)       18080                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)                (None, 700, 32)       42144                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)                (None, 700, 32)       54176                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 700, 96)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 700, 96)       384                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)                (None, 700, 48)       41520                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)               (None, 700, 44)       8316                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 700, 48)       192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 700, 44)       176                                          \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 700, 188)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)               (None, 700, 64)       60224                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 700, 108)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 700, 24)       8712                                         \n",
      "____________________________________________________________________________________________________\n",
      "OutputLayer (Conv1D)             (None, 700, 9)        225                                          \n",
      "====================================================================================================\n",
      "Total params: 305,249.0\n",
      "Trainable params: 304,497.0\n",
      "Non-trainable params: 752.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___\n",
    "### Train the model on training data against target training labels, show accuracy on validation data each epoch\n",
    "Here, the <b>val_loss</b> and <b>val_acc</b> are the loss and accuracy on the actual test data -- not a recommended practice but done here for the sake of reproducing previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5534 samples, validate on 514 samples\n",
      "Epoch 1/60\n",
      "84s - loss: 1.5615 - custom_acc: 0.3524 - val_loss: 0.8787 - val_custom_acc: 0.3066\n",
      "Epoch 2/60\n",
      "79s - loss: 1.0136 - custom_acc: 0.3772 - val_loss: 0.9357 - val_custom_acc: 0.3226\n",
      "Epoch 3/60\n",
      "80s - loss: 0.8071 - custom_acc: 0.4526 - val_loss: 0.9816 - val_custom_acc: 0.2257\n",
      "Epoch 4/60\n",
      "80s - loss: 0.7827 - custom_acc: 0.5047 - val_loss: 0.6719 - val_custom_acc: 0.2453\n",
      "Epoch 5/60\n",
      "81s - loss: 0.6861 - custom_acc: 0.5360 - val_loss: 0.6786 - val_custom_acc: 0.2224\n",
      "Epoch 6/60\n",
      "82s - loss: 0.6779 - custom_acc: 0.5568 - val_loss: 0.6884 - val_custom_acc: 0.2332\n",
      "Epoch 7/60\n",
      "85s - loss: 0.6497 - custom_acc: 0.5563 - val_loss: 0.6726 - val_custom_acc: 0.2671\n",
      "Epoch 8/60\n",
      "84s - loss: 0.6023 - custom_acc: 0.5764 - val_loss: 0.6358 - val_custom_acc: 0.2532\n",
      "Epoch 9/60\n",
      "83s - loss: 0.5489 - custom_acc: 0.5871 - val_loss: 0.5629 - val_custom_acc: 0.2773\n",
      "Epoch 10/60\n",
      "80s - loss: 0.5138 - custom_acc: 0.5906 - val_loss: 0.5660 - val_custom_acc: 0.2806\n",
      "Epoch 11/60\n",
      "79s - loss: 0.4864 - custom_acc: 0.5978 - val_loss: 0.5789 - val_custom_acc: 0.2778\n",
      "Epoch 12/60\n",
      "81s - loss: 0.4908 - custom_acc: 0.6001 - val_loss: 0.6153 - val_custom_acc: 0.2540\n",
      "Epoch 13/60\n",
      "80s - loss: 0.4789 - custom_acc: 0.6122 - val_loss: 0.5694 - val_custom_acc: 0.2917\n",
      "Epoch 14/60\n",
      "81s - loss: 0.4885 - custom_acc: 0.6186 - val_loss: 0.5479 - val_custom_acc: 0.3039\n",
      "Epoch 15/60\n",
      "79s - loss: 0.4612 - custom_acc: 0.6350 - val_loss: 0.5081 - val_custom_acc: 0.3182\n",
      "Epoch 16/60\n",
      "78s - loss: 0.4751 - custom_acc: 0.6351 - val_loss: 0.4373 - val_custom_acc: 0.5247\n",
      "Epoch 17/60\n",
      "81s - loss: 0.4430 - custom_acc: 0.6433 - val_loss: 0.4760 - val_custom_acc: 0.3735\n",
      "Epoch 18/60\n",
      "80s - loss: 0.4279 - custom_acc: 0.6472 - val_loss: 0.5473 - val_custom_acc: 0.3083\n",
      "Epoch 19/60\n",
      "81s - loss: 0.4493 - custom_acc: 0.6443 - val_loss: 0.4138 - val_custom_acc: 0.5222\n",
      "Epoch 20/60\n",
      "80s - loss: 0.4117 - custom_acc: 0.6543 - val_loss: 0.3940 - val_custom_acc: 0.5459\n",
      "Epoch 21/60\n",
      "80s - loss: 0.4104 - custom_acc: 0.6557 - val_loss: 0.4173 - val_custom_acc: 0.4945\n",
      "Epoch 22/60\n",
      "83s - loss: 0.4148 - custom_acc: 0.6518 - val_loss: 0.3654 - val_custom_acc: 0.5957\n",
      "Epoch 23/60\n",
      "83s - loss: 0.4100 - custom_acc: 0.6534 - val_loss: 0.3578 - val_custom_acc: 0.6105\n",
      "Epoch 24/60\n",
      "79s - loss: 0.3986 - custom_acc: 0.6607 - val_loss: 0.3589 - val_custom_acc: 0.6036\n",
      "Epoch 25/60\n",
      "79s - loss: 0.3951 - custom_acc: 0.6606 - val_loss: 0.3617 - val_custom_acc: 0.5946\n",
      "Epoch 26/60\n",
      "78s - loss: 0.3933 - custom_acc: 0.6630 - val_loss: 0.3572 - val_custom_acc: 0.5948\n",
      "Epoch 27/60\n",
      "79s - loss: 0.4016 - custom_acc: 0.6562 - val_loss: 0.3702 - val_custom_acc: 0.6050\n",
      "Epoch 28/60\n",
      "77s - loss: 0.4044 - custom_acc: 0.6601 - val_loss: 0.3614 - val_custom_acc: 0.5962\n",
      "Epoch 29/60\n",
      "77s - loss: 0.4330 - custom_acc: 0.6379 - val_loss: 0.5457 - val_custom_acc: 0.3328\n",
      "Epoch 30/60\n",
      "80s - loss: 0.4116 - custom_acc: 0.6555 - val_loss: 0.3899 - val_custom_acc: 0.5357\n",
      "Epoch 31/60\n",
      "78s - loss: 0.3871 - custom_acc: 0.6679 - val_loss: 0.3676 - val_custom_acc: 0.5699\n",
      "Epoch 32/60\n",
      "78s - loss: 0.3825 - custom_acc: 0.6715 - val_loss: 0.3549 - val_custom_acc: 0.5971\n",
      "Epoch 33/60\n",
      "78s - loss: 0.3805 - custom_acc: 0.6728 - val_loss: 0.3581 - val_custom_acc: 0.5958\n",
      "Epoch 34/60\n",
      "78s - loss: 0.3788 - custom_acc: 0.6743 - val_loss: 0.3633 - val_custom_acc: 0.5897\n",
      "Epoch 35/60\n",
      "79s - loss: 0.3782 - custom_acc: 0.6747 - val_loss: 0.3594 - val_custom_acc: 0.5881\n",
      "Epoch 36/60\n",
      "80s - loss: 0.3776 - custom_acc: 0.6749 - val_loss: 0.3583 - val_custom_acc: 0.5892\n",
      "Epoch 37/60\n",
      "79s - loss: 0.3768 - custom_acc: 0.6758 - val_loss: 0.3558 - val_custom_acc: 0.5905\n",
      "Epoch 38/60\n",
      "84s - loss: 0.3764 - custom_acc: 0.6759 - val_loss: 0.3565 - val_custom_acc: 0.5830\n",
      "Epoch 39/60\n",
      "84s - loss: 0.3762 - custom_acc: 0.6760 - val_loss: 0.3460 - val_custom_acc: 0.6065\n",
      "Epoch 40/60\n",
      "86s - loss: 0.3751 - custom_acc: 0.6774 - val_loss: 0.3425 - val_custom_acc: 0.6135\n",
      "Epoch 41/60\n",
      "83s - loss: 0.3751 - custom_acc: 0.6771 - val_loss: 0.3408 - val_custom_acc: 0.6175\n",
      "Epoch 42/60\n",
      "82s - loss: 0.3751 - custom_acc: 0.6773 - val_loss: 0.3324 - val_custom_acc: 0.6324\n",
      "Epoch 43/60\n",
      "79s - loss: 0.3755 - custom_acc: 0.6767 - val_loss: 0.3294 - val_custom_acc: 0.6363\n",
      "Epoch 44/60\n",
      "80s - loss: 0.3742 - custom_acc: 0.6783 - val_loss: 0.3284 - val_custom_acc: 0.6400\n",
      "Epoch 45/60\n",
      "81s - loss: 0.3743 - custom_acc: 0.6780 - val_loss: 0.3334 - val_custom_acc: 0.6299\n",
      "Epoch 46/60\n",
      "77s - loss: 0.3750 - custom_acc: 0.6766 - val_loss: 0.3267 - val_custom_acc: 0.6429\n",
      "Epoch 47/60\n",
      "77s - loss: 0.3738 - custom_acc: 0.6785 - val_loss: 0.3298 - val_custom_acc: 0.6349\n",
      "Epoch 48/60\n",
      "80s - loss: 0.3740 - custom_acc: 0.6778 - val_loss: 0.3270 - val_custom_acc: 0.6396\n",
      "Epoch 49/60\n",
      "81s - loss: 0.3740 - custom_acc: 0.6781 - val_loss: 0.3296 - val_custom_acc: 0.6341\n",
      "Epoch 50/60\n",
      "81s - loss: 0.3739 - custom_acc: 0.6781 - val_loss: 0.3256 - val_custom_acc: 0.6428\n",
      "Epoch 51/60\n",
      "80s - loss: 0.3729 - custom_acc: 0.6791 - val_loss: 0.3260 - val_custom_acc: 0.6405\n",
      "Epoch 52/60\n",
      "79s - loss: 0.3728 - custom_acc: 0.6791 - val_loss: 0.3316 - val_custom_acc: 0.6295\n",
      "Epoch 53/60\n",
      "81s - loss: 0.3743 - custom_acc: 0.6770 - val_loss: 0.3253 - val_custom_acc: 0.6451\n",
      "Epoch 54/60\n",
      "81s - loss: 0.3734 - custom_acc: 0.6786 - val_loss: 0.3358 - val_custom_acc: 0.6231\n",
      "Epoch 55/60\n",
      "79s - loss: 0.3723 - custom_acc: 0.6800 - val_loss: 0.3360 - val_custom_acc: 0.6239\n",
      "Epoch 56/60\n",
      "80s - loss: 0.3727 - custom_acc: 0.6791 - val_loss: 0.3293 - val_custom_acc: 0.6339\n",
      "Epoch 57/60\n",
      "81s - loss: 0.3722 - custom_acc: 0.6796 - val_loss: 0.3244 - val_custom_acc: 0.6444\n",
      "Epoch 58/60\n",
      "83s - loss: 0.3717 - custom_acc: 0.6803 - val_loss: 0.3279 - val_custom_acc: 0.6380\n",
      "Epoch 59/60\n",
      "84s - loss: 0.3715 - custom_acc: 0.6801 - val_loss: 0.3235 - val_custom_acc: 0.6447\n",
      "Epoch 60/60\n",
      "84s - loss: 0.3740 - custom_acc: 0.6771 - val_loss: 0.3328 - val_custom_acc: 0.6326\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# verbose: 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "hist = model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, verbose=2,\n",
    "                 batch_size=MINIBATCH, validation_data=(test_x, test_y),\n",
    "                callbacks=[keras.callbacks.LearningRateScheduler(lr_sched)])\n",
    "print(\"Done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved.\n"
     ]
    }
   ],
   "source": [
    "model.save(SAVE_FILE)\n",
    "print(\"model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x36369860>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGm/VlHeYQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11400630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc = list(hist.history.values())[2]\n",
    "plt.plot(range(EPOCHS), test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___\n",
    "## Test on cb513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_acc = model.evaluate(test_x, test_y)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "prediction = model.predict(test_x[i:i+1])\n",
    "prediction = prediction.reshape(700, 9)\n",
    "print(\"Shape:\", prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Expected:\\n\")\n",
    "_ = cullpdb_loader.print_residues(test_x[i], labels=test_y[i], two_d=True)\n",
    "print(\"\\nPredicted:\\n\")\n",
    "_ = cullpdb_loader.print_residues(test_x[i], labels=prediction, two_d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sdscbio-gpu]",
   "language": "python",
   "name": "conda-env-sdscbio-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
